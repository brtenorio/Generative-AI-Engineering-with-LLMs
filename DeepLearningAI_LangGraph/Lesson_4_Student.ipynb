{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5789bc3-b1ae-42c7-94a8-2ef4f89946fc",
   "metadata": {},
   "source": [
    "# Lesson 4: Persistence and Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5762271-8736-4e94-9444-8c92bd0e8074",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0168aee-bce9-4d60-b827-f86a88187e31",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da06a64f-a2d5-4a66-8090-9ada0930c684",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "tool = TavilySearchResults(max_results=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2589c5b6-6cc2-4594-9a17-dccdcf676054",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c033522-d2fc-41ac-8e3c-5e35872bf88d",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2ba84ec-c172-4de7-ac55-e3158a531b23",
   "metadata": {
    "height": 574
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, model, tools, checkpointer, system=\"\"):\n",
    "        self.system = system\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(\"llm\", self.call_openai)\n",
    "        graph.add_node(\"action\", self.take_action)\n",
    "        graph.add_conditional_edges(\"llm\", self.exists_action, {True: \"action\", False: END})\n",
    "        graph.add_edge(\"action\", \"llm\")\n",
    "        graph.set_entry_point(\"llm\")\n",
    "        self.graph = graph.compile(checkpointer=checkpointer)\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "    def call_openai(self, state: AgentState):\n",
    "        messages = state['messages']\n",
    "        if self.system:\n",
    "            messages = [SystemMessage(content=self.system)] + messages\n",
    "        message = self.model.invoke(messages)\n",
    "        return {'messages': [message]}\n",
    "\n",
    "    def exists_action(self, state: AgentState):\n",
    "        result = state['messages'][-1]\n",
    "        return len(result.tool_calls) > 0\n",
    "\n",
    "    def take_action(self, state: AgentState):\n",
    "        tool_calls = state['messages'][-1].tool_calls\n",
    "        results = []\n",
    "        for t in tool_calls:\n",
    "            print(f\"Calling: {t}\")\n",
    "            result = self.tools[t['name']].invoke(t['args'])\n",
    "            results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "        print(\"Back to the model!\")\n",
    "        return {'messages': results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "876d5092-b8ef-4e38-b4d7-0e80c609bf7a",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "\"\"\"\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "abot = Agent(model, [tool], system=prompt, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10084a02-2928-4945-9f7c-ad3f5b33caf7",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in sf?\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "714d1205-f8fc-4912-b148-2a45da99219c",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83588e70-254f-4f83-a510-c8ae81e729b0",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_bmfLa92f6oAIKN9KvXtqbKDz', 'function': {'arguments': '{\"query\":\"current weather in San Francisco\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 151, 'total_tokens': 173, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-3ea306c3-80f5-4946-939e-5f5bbcfd0a48-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_bmfLa92f6oAIKN9KvXtqbKDz'}])]\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_bmfLa92f6oAIKN9KvXtqbKDz'}\n",
      "Back to the model!\n",
      "[ToolMessage(content=\"[{'url': 'https://world-weather.info/forecast/usa/san_francisco/june-2025/', 'content': 'Detailed ‚ö° San Francisco Weather Forecast for June 2025 ‚Äì day/night üå°Ô∏è ... Monday, 30 June. +54¬∞. Day. +63¬∞. Broken clouds. Extended weather forecast in'}, {'url': 'https://forecast.weather.gov/zipcity.php?inputstring=San+Francisco,CA', 'content': 'Click map to change the forecast location\\\\n\\\\nLoading map...\\\\n\\\\nForecast Area\\\\n\\\\nDisclaimer\\\\n\\\\nTiles ¬©ESRI\\\\n\\\\nToggle menu\\\\n\\\\n## ABOUT THIS FORECAST\\\\n\\\\nPoint Forecast:\\\\n\\\\nSan Francisco CA  \\\\n 37.77¬∞N 122.41¬∞W (Elev. 131 ft)\\\\n\\\\nLast Update:\\\\n\\\\n8:54 am PDT Jun 30, 2025\\\\n\\\\nForecast Valid:\\\\n\\\\n12pm PDT Jun 30, 2025-6pm PDT Jul 6, 2025\\\\n\\\\nForecast Discussion\\\\n\\\\nGet as KML\\\\nGet as XML\\\\n\\\\n## Additional Resources\\\\n\\\\n#### Radar & Satellite Image\\\\n\\\\nLink to Local Radar Data Link to Satellite Data\\\\n\\\\n#### Hourly Weather Forecast [...] Lat:37.77056¬∞NLon:122.42694¬∞WElev:150.0ft.\\\\n\\\\nNA\\\\n\\\\n59¬∞F\\\\n\\\\n15¬∞C\\\\n\\\\n|  |  |\\\\n| --- | --- |\\\\n| Humidity | 75% |\\\\n| Wind Speed | NA NA MPH |\\\\n| Barometer | NA |\\\\n| Dewpoint | 51¬∞F (11¬∞C) |\\\\n| Visibility | NA |\\\\n| Last update | 30 Jun 11:43 AM PDT |\\\\n\\\\nMore Information:\\\\n\\\\nLocal Forecast OfficeMore Local Wx3 Day HistoryHourly Weather Forecast\\\\n\\\\nExtended Forecast for\\\\n\\\\n## San Francisco CA\\\\n\\\\n This Afternoon\\\\n\\\\n  This Afternoon: Sunny, with a high near 67. West southwest wind 7 to 11 mph. \\\\n\\\\n  High: 67 ¬∞F\\\\n\\\\n  Sunny\\\\n Tonight [...] #### National Digital Forecast Database\\\\n\\\\nNational Digital Forecast Database Maximum Temperature Forecast\\\\n\\\\nHigh Temperature\\\\n\\\\nNational Digital Forecast Database Weather Element Forecast\\\\n\\\\nChance of Precipitation\\\\n\\\\n## SAN FRANCISCO DOWNTOWN (SFOC1)\\\\n\\\\nNA\\\\n\\\\n59¬∞F\\\\n\\\\n15¬∞C\\\\n\\\\n|  |  |\\\\n| --- | --- |\\\\n| Humidity | 75% |\\\\n| Wind Speed | NA NA MPH |\\\\n| Barometer | NA |\\\\n| Dewpoint | 51¬∞F (11¬∞C) |\\\\n| Visibility | NA |\\\\n| Last update | 30 Jun 11:43 AM PDT |\\\\n\\\\nMore Information:'}]\", name='tavily_search_results_json', tool_call_id='call_bmfLa92f6oAIKN9KvXtqbKDz')]\n",
      "[AIMessage(content='The current weather in San Francisco is sunny with a high near 67¬∞F (approximately 19¬∞C). The wind is coming from the west-southwest at 7 to 11 mph. The temperature right now is around 59¬∞F (15¬∞C), with a humidity level of 75%.', response_metadata={'token_usage': {'completion_tokens': 61, 'prompt_tokens': 764, 'total_tokens': 825, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_07871e2ad8', 'finish_reason': 'stop', 'logprobs': None}, id='run-d7b6036e-4034-4a7c-98b5-02e49c47c7d9-0')]\n"
     ]
    }
   ],
   "source": [
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v['messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cb3ef4c-58b3-401b-b104-0d51e553d982",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_CUeHKeF1Eu9rrdZa9KpxAAYF', 'function': {'arguments': '{\"query\":\"current weather in Los Angeles\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 837, 'total_tokens': 859, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_07871e2ad8', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-46b8545b-b864-4825-a2db-a050bdfbd281-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in Los Angeles'}, 'id': 'call_CUeHKeF1Eu9rrdZa9KpxAAYF'}])]}\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'current weather in Los Angeles'}, 'id': 'call_CUeHKeF1Eu9rrdZa9KpxAAYF'}\n",
      "Back to the model!\n",
      "{'messages': [ToolMessage(content='[{\\'url\\': \\'https://www.weather25.com/north-america/usa/california/los-angeles?page=month&month=June\\', \\'content\\': \\'weather25.com\\\\nSearch\\\\nweather in United States\\\\nRemove from your favorite locations\\\\nAdd to my locations\\\\nShare\\\\nweather in United States\\\\n\\\\n# Los Angeles weather in June 2025\\\\n\\\\nPartly cloudy\\\\nPartly cloudy\\\\nPartly cloudy\\\\nCloudy\\\\nClear\\\\nClear\\\\nClear\\\\nClear\\\\nClear\\\\nClear\\\\nClear\\\\nClear\\\\nClear\\\\nClear\\\\n\\\\n## The average weather in Los Angeles in June\\\\n\\\\nThe temperatures in Los Angeles in June are comfortable with low of 17¬∞C and and high up to 27¬∞C. [...] As it is almost never rain during June in Los Angeles the weather is perfect for hanging out outside and exploring all that Los Angeles has to offer.\\\\n\\\\nOur weather forecast can give you a great sense of what weather to expect in Los Angeles in June 2025.\\\\n\\\\nIf you‚Äôre planning to visit Los Angeles in the near future, we highly recommend that you review the 14 day weather forecast for Los Angeles before you arrive.\\\\n\\\\nTemperatures\\\\nRainy Days\\\\nSnowy Days\\\\nDry Days\\\\nRainfall\\\\n11.8 [...] Partly cloudy\\\\nPartly cloudy\\\\nPartly cloudy\\\\nSunny\\\\nSunny\\\\nSunny\\\\nSunny\\\\nSunny\\\\nSunny\\\\nSunny\\\\nSunny\\\\nSunny\\\\nPartly cloudy\\\\nCloudy\\\\nPartly cloudy\\\\nPartly cloudy\\\\nSunny\\\\nPartly cloudy\\\\nSunny\\\\nSunny\\\\nSunny\\\\nSunny\\\\nPartly cloudy\\\\nSunny\\\\nCloudy\\\\nCloudy\\\\nSunny\\\\nCloudy\\\\nSunny\\\\nPartly cloudy\\\\n\\\\n## Explore the weather in Los Angeles in other months\\\\n\\\\n## Los Angeles annual weather\\'}, {\\'url\\': \\'https://www.timeanddate.com/weather/usa/los-angeles/historic?month=6&year=2025\\', \\'content\\': \\'| 9:53 pm |  | 63 ¬∞F | Overcast. | 7 mph | ‚Üë | 78% | 29.93 \"Hg | 10 mi |\\\\n| 10:25 pm |  | 62 ¬∞F | Passing clouds. | 5 mph | ‚Üë | 83% | 29.94 \"Hg | 10 mi |\\\\n| 10:53 pm |  | 62 ¬∞F | Passing clouds. | 5 mph | ‚Üë | 80% | 29.94 \"Hg | 10 mi |\\\\n| 11:53 pm |  | 62 ¬∞F | Clear. | 5 mph | ‚Üë | 83% | 29.94 \"Hg | 10 mi |\\\\n|  |  |  |  |  |  |  |  |  |\\\\n| --- | --- | --- | --- | --- | --- | --- | --- | --- |\\\\n| Weather by CustomWeather, ¬© 2025 | | | | | | | | | [...] | 9:53 am |  | 75 ¬∞F | Sunny. | 3 mph | ‚Üë | 55% | 29.95 \"Hg | 10 mi |\\\\n| 10:53 am |  | 72 ¬∞F | Sunny. | 7 mph | ‚Üë | 66% | 29.94 \"Hg | 10 mi |\\\\n| 11:53 am |  | 72 ¬∞F | Sunny. | 5 mph | ‚Üë | 66% | 29.93 \"Hg | 9 mi |\\\\n| 12:53 pm |  | 75 ¬∞F | Sunny. | 7 mph | ‚Üë | 54% | 29.91 \"Hg | 10 mi |\\\\n| 1:53 pm |  | 78 ¬∞F | Sunny. | 10 mph | ‚Üë | 43% | 29.89 \"Hg | 10 mi |\\\\n| 2:53 pm |  | 77 ¬∞F | Sunny. | 13 mph | ‚Üë | 47% | 29.86 \"Hg | 10 mi |\\\\n| 3:53 pm |  | 73 ¬∞F | Sunny. | 10 mph | ‚Üë | 59% | 29.86 \"Hg | 10 mi | [...] | 4:53 pm |  | 71 ¬∞F | Sunny. | 8 mph | ‚Üë | 68% | 29.86 \"Hg | 10 mi |\\\\n| 5:53 pm |  | 70 ¬∞F | Sunny. | 15 mph | ‚Üë | 66% | 29.86 \"Hg | 10 mi |\\\\n| 6:53 pm |  | 67 ¬∞F | Sunny. | 15 mph | ‚Üë | 76% | 29.87 \"Hg | 10 mi |\\\\n| 7:53 pm |  | 65 ¬∞F | Passing clouds. | 14 mph | ‚Üë | 78% | 29.88 \"Hg | 10 mi |\\\\n| 8:33 pm |  | 64 ¬∞F | Passing clouds. | 8 mph | ‚Üë | 81% | 29.90 \"Hg | 10 mi |\\\\n| 8:53 pm |  | 63 ¬∞F | Overcast. | 8 mph | ‚Üë | 81% | 29.90 \"Hg | 10 mi |\\'}]', name='tavily_search_results_json', tool_call_id='call_CUeHKeF1Eu9rrdZa9KpxAAYF')]}\n",
      "{'messages': [AIMessage(content='The current weather in Los Angeles is sunny with a temperature around 75¬∞F (approximately 24¬∞C). The wind is blowing at 7 to 13 mph, and the humidity is around 54% to 66%.', response_metadata={'token_usage': {'completion_tokens': 46, 'prompt_tokens': 1995, 'total_tokens': 2041, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_07871e2ad8', 'finish_reason': 'stop', 'logprobs': None}, id='run-64acb673-6bba-4668-95b9-8844a4d5c777-0')]}\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What about in la?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc3293b7-a50c-43c8-a022-8975e1e444b8",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content=\"Los Angeles is currently warmer than San Francisco. Los Angeles has a temperature around 75¬∞F (approximately 24¬∞C), while San Francisco's temperature is about 59¬∞F (15¬∞C).\", response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 2053, 'total_tokens': 2092, 'prompt_tokens_details': {'cached_tokens': 1920, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_07871e2ad8', 'finish_reason': 'stop', 'logprobs': None}, id='run-41c6931b-544d-4186-8fa9-e4416d00889d-0')]}\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Which one is warmer?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0722c3d4-4cbf-43bf-81b0-50f634c4ce61",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content=\"Could you please clarify what you're comparing to determine which is warmer? Are you comparing two specific locations, types of clothing, materials, or something else? Let me know so I can provide the appropriate information.\", response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 149, 'total_tokens': 192, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_f9f4fb6dbf', 'finish_reason': 'stop', 'logprobs': None}, id='run-501fb361-d4bb-4d02-9061-0e7a66c87b30-0')]}\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Which one is warmer?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace59a36-3941-459e-b9d1-ac5a4a1ed3ae",
   "metadata": {},
   "source": [
    "## Streaming tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b2f82fe-3ec4-4917-be51-9fb10d1317fa",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.aiosqlite import AsyncSqliteSaver\n",
    "\n",
    "memory = AsyncSqliteSaver.from_conn_string(\":memory:\")\n",
    "abot = Agent(model, [tool], system=prompt, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee0fe1c7-77e2-499c-a2f9-1f739bb6ddf0",
   "metadata": {
    "height": 200
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_8etfZasfe0eUw99Q9qqzCQ0N'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/langchain_core/_api/beta_decorator.py:87: LangChainBetaWarning: This API is in beta and may change in the future.\n",
      "  warn_beta(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Back to the model!\n",
      "The| current| weather| in| San| Francisco| is| sunny|,| with| a| high| near| |67|¬∞F| (|approximately| |19|¬∞C|).| The| wind| is| coming| from| the| west| southwest| at| |7| to| |11| mph|.| The| temperature| is| currently| around| |59|¬∞F| (|15|¬∞C|)| with| |75|%| humidity|.|"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in SF?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "async for event in abot.graph.astream_events({\"messages\": messages}, thread, version=\"v1\"):\n",
    "    kind = event[\"event\"]\n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        content = event[\"data\"][\"chunk\"].content\n",
    "        if content:\n",
    "            # Empty content in the context of OpenAI means\n",
    "            # that the model is asking for a tool to be invoked.\n",
    "            # So we only print non-empty content\n",
    "            print(content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f303b1-a4d0-408c-8cc0-515ff980717f",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
